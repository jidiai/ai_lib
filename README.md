# å¹³å°åœ°å€
# [jidi_ai](http://www.jidiai.cn/)

## é¡¹ç›®ä¾èµ–

- `Python 3.7.5`
- `gym` https://github.com/openai/gym
- `gfootball` https://github.com/google-research/football
- `miniworld` https://github.com/maximecb/gym-miniworld#installation
- `minigrid` https://github.com/maximecb/gym-minigrid
- `Multi-Agent Particle Environment` https://github.com/openai/multiagent-particle-envs
- `Overcooked-AI` https://github.com/HumanCompatibleAI/overcooked_ai
- `MAgent` https://www.pettingzoo.ml/magent
  
  (Using `pip install 'pettingzoo[magent]'` if you are using zsh; 
  Using render_from_log.py for MAgent local render)
- `Torch 1.7.0` å¯é€‰
  - æ”¯æŒæäº¤Torchè®­ç»ƒåŽçš„æ¨¡åž‹.pthé™„å±žæ–‡ä»¶

## ç›®å½•ç»“æž„

```
|-- platform_lib
	|-- README.md
	|-- run_log.py		// æœ¬åœ°è°ƒè¯•è¿è¡ŒçŽ¯å¢ƒ
	|-- examples	// æäº¤è¿è¡Œæ–‡ä»¶ç¤ºä¾‹	éœ€åŒ…å« my_controller å‡½æ•°è¾“å‡ºpolicy
	    |-- random.py  // éšæœºç­–ç•¥ éœ€æ ¹æ®çŽ¯å¢ƒåŠ¨ä½œæ˜¯å¦è¿žç»­ è°ƒæ•´ is_act_continuous çš„å€¼
	|-- replay		// renderå·¥å…·ï¼Œç”¨äºŽéžgymçŽ¯å¢ƒï¼Œæ‰“å¼€replay.htmlä¸Šä¼ run_log å­˜å‚¨çš„.jsonæ–‡ä»¶ 
	|-- env		// æ¸¸æˆçŽ¯å¢ƒ 
	|	|-- simulators		// æ¨¡æ‹Ÿå™¨
	|	|	|-- game.py
	|	|	|-- gridgame.py // ç½‘æ ¼ç±»æ¨¡æ‹Ÿå™¨æŽ¥å£
	|	|-- obs_interfaces		// observation è§‚æµ‹ç±»æŽ¥å£
	|	|	|-- observation.py		// ç›®å‰æ”¯æŒGrid Vector
	|	|-- config.ini		// ç›¸å…³é…ç½®æ–‡ä»¶
	|	|-- chooseenv.py 
	|	|-- snakes.py
	|	|-- gobang.py
	|	|-- reversi.py
	|	|-- sokoban.py
	|	|-- ccgame.py

```

## å¹³å°æäº¤è¯´æ˜Ž
1. å¡«å†™ç®—æ³•åç§°æˆ–æè¿°ï¼Œé€‰æ‹©æäº¤çŽ¯å¢ƒ
2. ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ã€‚
- å…¶ä¸­å¿…é¡»åŒ…å«ä¸€ä¸ªè¿è¡Œæ–‡ä»¶ï¼Œè¿è¡Œæ–‡ä»¶éœ€åŒ…å«`my_controller` å‡½æ•°çš„ä¸€ä¸ª`submission.py`æ–‡ä»¶ã€‚
- é™„å±žæ–‡ä»¶æ”¯æŒ`.pth` `.py`ç±»åž‹æ–‡ä»¶ã€‚å¤§å°ä¸è¶…è¿‡100Mï¼Œä¸ªæ•°ä¸è¶…è¿‡5ä¸ªã€‚ 


# ç®—æ³•æ¡†æž¶
To train a reinforcement learning agent, you can use the code provided in the /examples directory. 
If you want to use a parallel framework, we also provide two frameworks-Tianshou and Malib. 
in this repository, these two frameworks been slightly modified in order to interact with JidiEnv. 

## JidiAlgo ðŸ‘‰è¯·çœ‹ examples
## tianshou ðŸ‘‰è¯·çœ‹ tianshou-master
## malib ðŸ‘‰è¯·çœ‹ malib-main

A example: Algo-DQN & JidiEnv-Cartpole & Framework-Tianshow:
> python tianshou-master/demo.py